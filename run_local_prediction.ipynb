{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Local Race Classification Prediction\n",
        "\n",
        "This notebook loads the local Keras `.h5` race-classification model and performs predictions on images from your machine. Optionally, you can use YOLOv8 to first detect people/faces and then classify the cropped regions.\n",
        "\n",
        "- Update `MODEL_PATH` if your `.h5` name differs\n",
        "- Update `TEST_IMAGE_PATH` to any local image file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuration\n",
        "# Adjust these if your filenames/paths differ\n",
        "MODEL_PATH = \"/Users/jeron/projects/Race-Classification/Race Classification Model.h5\"\n",
        "TEST_IMAGE_PATH = \"/Users/jeron/Pictures/sample.jpg\"  # Change to a local image file\n",
        "CLASS_NAMES = [\"Black\", \"East Asian\", \"White\"]  # match the training setup\n",
        "\n",
        "print(tf.__version__)\n",
        "print(f\"Model path exists: {os.path.exists(MODEL_PATH)}\")\n",
        "print(f\"Test image exists: {os.path.exists(TEST_IMAGE_PATH)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Keras model (.h5)\n",
        "assert os.path.exists(MODEL_PATH), f\"Model not found at {MODEL_PATH}\"\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def preprocess_image(img_path: str, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:\n",
        "    \"\"\"Load and preprocess image for the classifier.\"\"\"\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    arr = image.img_to_array(img)\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    arr = arr / 255.0\n",
        "    return arr\n",
        "\n",
        "\n",
        "def predict_image(img_path: str) -> Tuple[str, np.ndarray]:\n",
        "    arr = preprocess_image(img_path)\n",
        "    preds = model.predict(arr)\n",
        "    idx = int(np.argmax(preds, axis=-1)[0])\n",
        "    return CLASS_NAMES[idx], preds[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo: predict on a single image\n",
        "assert os.path.exists(TEST_IMAGE_PATH), f\"Test image not found: {TEST_IMAGE_PATH}\"\n",
        "label, probs = predict_image(TEST_IMAGE_PATH)\n",
        "print(\"Predicted:\", label)\n",
        "print(\"Probabilities:\", {name: float(p) for name, p in zip(CLASS_NAMES, probs)})\n",
        "\n",
        "img = image.load_img(TEST_IMAGE_PATH)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Predicted: {label}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: YOLOv8 detection â†’ classify crops\n",
        "# pip install ultralytics opencv-python  # run in your environment if needed\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "YOLO_MODEL = \"yolov8m.pt\"  # change to 'yolov8n.pt' for faster CPU inference\n",
        "\n",
        "# Path to an image with people/faces\n",
        "DETECT_IMAGE_PATH = TEST_IMAGE_PATH  # reuse, or set another file path\n",
        "assert os.path.exists(DETECT_IMAGE_PATH), f\"Image not found: {DETECT_IMAGE_PATH}\"\n",
        "\n",
        "# Load detector\n",
        "yolo = YOLO(YOLO_MODEL)\n",
        "\n",
        "# Read and run detection\n",
        "bgr = cv2.imread(DETECT_IMAGE_PATH)\n",
        "rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "res = yolo(rgb)[0]\n",
        "\n",
        "# Visualize detections\n",
        "plt.figure()\n",
        "plt.imshow(res.plot())\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLO detections\")\n",
        "plt.show()\n",
        "\n",
        "# Classify each detected person region\n",
        "predictions = []\n",
        "for box, cls_id in zip(res.boxes.xyxy.cpu().numpy(), res.boxes.cls.cpu().numpy().astype(int)):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    crop = rgb[y1:y2, x1:x2]\n",
        "    if crop.size == 0:\n",
        "        continue\n",
        "    # Save to temp and reuse same preprocessing\n",
        "    crop_path = \"/tmp/yolo_crop.jpg\"\n",
        "    cv2.imwrite(crop_path, cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
        "    label, probs = predict_image(crop_path)\n",
        "    predictions.append(((x1, y1, x2, y2), label, probs))\n",
        "\n",
        "# Show crops with predicted labels\n",
        "for (x1, y1, x2, y2), label, _ in predictions:\n",
        "    plt.figure()\n",
        "    plt.imshow(rgb[y1:y2, x1:x2])\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {label}\")\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
